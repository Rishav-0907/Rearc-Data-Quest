{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b0cccc",
   "metadata": {},
   "source": [
    "# BLS Data Analysis\n",
    "\n",
    "This notebook contains the analysis of BLS data and population data, including:\n",
    "1. Population statistics for years 2013-2018\n",
    "2. Best years analysis for each series_id\n",
    "3. Combined report for PRS30006032 and Q01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, year, when, max, mean, stddev, struct, trim\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set Java environment\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@17\"\n",
    "\n",
    "# Initialize Spark Session with specific configurations\n",
    "spark = SparkSession.builder \\n    .appName(\"BLS Data Analysis\") \\n    .config(\"spark.driver.memory\", \"4g\") \\n    .config(\"spark.executor.memory\", \"4g\") \\n    .config(\"spark.sql.warehouse.dir\", tempfile.mkdtemp()) \\n    .getOrCreate()\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket_name = os.getenv(\"S3_BUCKET_NAME\")\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Print Spark version and configuration\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Java version: {os.environ.get(\"JAVA_HOME\")}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
